# Enter your network definition here.
# Use Shift+Enter to update the visualization.
name: "ResNet-cifar10-double"
layer {
  name : "cifar"
  type : "Data"
  top : "data"
  top : "label"
  include {
    phase : TRAIN
  }
  transform_param {
    mean_file : "examples/cifar10/mean.binaryproto"
    scale: 0.00390625
    mirror: true
  }
  data_param {
    source : "examples/cifar10/cifar10_train_lmdb"
    batch_size : 100
    backend : LMDB
    prefetch: 32
  }
}
layer {
  name : "cifar"
  type : "Data"
  top : "data"
  top : "label"
  include {
    phase : TEST
  }
  transform_param {
    mean_file : "examples/cifar10/mean.binaryproto"
    scale: 0.00390625
  }
  data_param {
    source : "examples/cifar10/cifar10_test_lmdb"
    batch_size : 100
    backend : LMDB
  }
}
layer {
  name : "conv0"
  type : "Convolution"
  bottom : "data"
  top : "conv0"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 16
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "bn0"
  type: "BatchNorm"
  bottom: "conv0"
  top: "bn0"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "relu0"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "relu0"
  bottom : "bn0"
}

############################################
# 16x16

layer {
  name : "block1-conv1"
  type : "Convolution"
  bottom : "relu0"
  top : "block1-conv1"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 32
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block1-bn1"
  type: "BatchNorm"
  bottom: "block1-conv1"
  top: "block1-bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block1-relu1"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block1-relu1"
  bottom : "block1-bn1"
}

layer {
  name : "block1-conv2"
  type : "Convolution"
  bottom : "block1-relu1"
  top : "block1-conv2"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 32
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block1-bn2"
  type: "BatchNorm"
  bottom: "block1-conv2"
  top: "block1-bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block1-relu2"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block1-relu2"
  bottom : "block1-bn2"
}

layer {
  name: "block1-project"
  type: "Convolution"
  bottom: "relu0"
  top: "block1-project"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 32
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}

layer {
  name: "block1-res1"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block1-project"
  bottom: "block1-relu2"
  top: "block1-res1"
}


layer {
  name : "block1-conv3"
  type : "Convolution"
  bottom : "block1-res1"
  top : "block1-conv3"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 32
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block1-bn3"
  type: "BatchNorm"
  bottom: "block1-conv3"
  top: "block1-bn3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block1-relu3"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block1-relu3"
  bottom : "block1-bn3"
}

layer {
  name : "block1-conv4"
  type : "Convolution"
  bottom : "block1-relu3"
  top : "block1-conv4"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 32
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block1-bn4"
  type: "BatchNorm"
  bottom: "block1-conv4"
  top: "block1-bn4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block1-relu4"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block1-relu4"
  bottom : "block1-bn4"
}

layer {
  name: "block1-res2"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block1-res1"
  bottom: "block1-relu4"
  top: "block1-res2"
}

layer {
  name : "block1-conv5"
  type : "Convolution"
  bottom : "block1-res2"
  top : "block1-conv5"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 32
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block1-bn5"
  type: "BatchNorm"
  bottom: "block1-conv5"
  top: "block1-bn5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block1-relu5"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block1-relu5"
  bottom : "block1-bn5"
}

layer {
  name : "block1-conv6"
  type : "Convolution"
  bottom : "block1-relu5"
  top : "block1-conv6"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 32
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block1-bn6"
  type: "BatchNorm"
  bottom: "block1-conv6"
  top: "block1-bn6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block1-relu6"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  bottom : "block1-bn6"
  top : "block1-relu6"
}

layer {
  name: "block1-res3"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block1-res2"
  bottom: "block1-relu6"
  top: "block1-res3"
}


###########################################
# 8x8

layer {
  name : "block2-conv1"
  type : "Convolution"
  bottom : "block1-res3"
  top : "block2-conv1"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 64
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block2-bn1"
  type: "BatchNorm"
  bottom: "block2-conv1"
  top: "block2-bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block2-relu1"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block2-relu1"
  bottom : "block2-bn1"
}

layer {
  name : "block2-conv2"
  type : "Convolution"
  bottom : "block2-relu1"
  top : "block2-conv2"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 64
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block2-bn2"
  type: "BatchNorm"
  bottom: "block2-conv2"
  top: "block2-bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block2-relu2"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block2-relu2"
  bottom : "block2-bn2"
}

layer {
  name: "block2-project"
  type: "Convolution"
  bottom: "block1-res3"
  top: "block2-project"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 64
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}

layer {
  name: "block2-res1"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block2-project"
  bottom: "block2-relu2"
  top: "block2-res1"
}


layer {
  name : "block2-conv3"
  type : "Convolution"
  bottom : "block2-res1"
  top : "block2-conv3"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 64
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block2-bn3"
  type: "BatchNorm"
  bottom: "block2-conv3"
  top: "block2-bn3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block2-relu3"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block2-relu3"
  bottom : "block2-bn3"
}

layer {
  name : "block2-conv4"
  type : "Convolution"
  bottom : "block2-relu3"
  top : "block2-conv4"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 64
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block2-bn4"
  type: "BatchNorm"
  bottom: "block2-conv4"
  top: "block2-bn4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block2-relu4"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block2-relu4"
  bottom : "block2-bn4"
}

layer {
  name: "block2-res2"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block2-res1"
  bottom: "block2-relu4"
  top: "block2-res2"
}

layer {
  name : "block2-conv5"
  type : "Convolution"
  bottom : "block2-res2"
  top : "block2-conv5"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 64
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block2-bn5"
  type: "BatchNorm"
  bottom: "block2-conv5"
  top: "block2-bn5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block2-relu5"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block2-relu5"
  bottom : "block2-bn5"
}

layer {
  name : "block2-conv6"
  type : "Convolution"
  bottom : "block2-relu5"
  top : "block2-conv6"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 64
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block2-bn6"
  type: "BatchNorm"
  bottom: "block2-conv6"
  top: "block2-bn6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block2-relu6"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  bottom : "block2-bn6"
  top : "block2-relu6"
}

layer {
  name: "block2-res3"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block2-res2"
  bottom: "block2-relu6"
  top: "block2-res3"
}


###########################################
# 4x4

layer {
  name : "block3-conv1"
  type : "Convolution"
  bottom : "block2-res3"
  top : "block3-conv1"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 128
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block3-bn1"
  type: "BatchNorm"
  bottom: "block3-conv1"
  top: "block3-bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block3-relu1"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block3-relu1"
  bottom : "block3-bn1"
}

layer {
  name : "block3-conv2"
  type : "Convolution"
  bottom : "block3-relu1"
  top : "block3-conv2"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 128
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block3-bn2"
  type: "BatchNorm"
  bottom: "block3-conv2"
  top: "block3-bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block3-relu2"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block3-relu2"
  bottom : "block3-bn2"
}

layer {
  name: "block3-project"
  type: "Convolution"
  bottom: "block2-res3"
  top: "block3-project"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 128
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}

layer {
  name: "block3-res1"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block3-project"
  bottom: "block3-relu2"
  top: "block3-res1"
}


layer {
  name : "block3-conv3"
  type : "Convolution"
  bottom : "block3-res1"
  top : "block3-conv3"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 128
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block3-bn3"
  type: "BatchNorm"
  bottom: "block3-conv3"
  top: "block3-bn3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block3-relu3"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block3-relu3"
  bottom : "block3-bn3"
}

layer {
  name : "block3-conv4"
  type : "Convolution"
  bottom : "block3-relu3"
  top : "block3-conv4"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 128
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block3-bn4"
  type: "BatchNorm"
  bottom: "block3-conv4"
  top: "block3-bn4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block3-relu4"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block3-relu4"
  bottom : "block3-bn4"
}

layer {
  name: "block3-res2"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block3-res1"
  bottom: "block3-relu4"
  top: "block3-res2"
}

layer {
  name : "block3-conv5"
  type : "Convolution"
  bottom : "block3-res2"
  top : "block3-conv5"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 128
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block3-bn5"
  type: "BatchNorm"
  bottom: "block3-conv5"
  top: "block3-bn5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block3-relu5"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block3-relu5"
  bottom : "block3-bn5"
}

layer {
  name : "block3-conv6"
  type : "Convolution"
  bottom : "block3-relu5"
  top : "block3-conv6"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 128
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block3-bn6"
  type: "BatchNorm"
  bottom: "block3-conv6"
  top: "block3-bn6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block3-relu6"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  bottom : "block3-bn6"
  top : "block3-relu6"
}

layer {
  name: "block3-res3"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block3-res2"
  bottom: "block3-relu6"
  top: "block3-res3"
}


###########################################
# 2x2

layer {
  name : "block4-conv1"
  type : "Convolution"
  bottom : "block3-res3"
  top : "block4-conv1"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 256
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block4-bn1"
  type: "BatchNorm"
  bottom: "block4-conv1"
  top: "block4-bn1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block4-relu1"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block4-relu1"
  bottom : "block4-bn1"
}

layer {
  name : "block4-conv2"
  type : "Convolution"
  bottom : "block4-relu1"
  top : "block4-conv2"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 256
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block4-bn2"
  type: "BatchNorm"
  bottom: "block4-conv2"
  top: "block4-bn2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block4-relu2"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block4-relu2"
  bottom : "block4-bn2"
}

layer {
  name: "block4-project"
  type: "Convolution"
  bottom: "block3-res3"
  top: "block4-project"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 256
    pad : 1
    kernel_size : 3
    stride : 2
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}

layer {
  name: "block4-res1"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block4-project"
  bottom: "block4-relu2"
  top: "block4-res1"
}


layer {
  name : "block4-conv3"
  type : "Convolution"
  bottom : "block4-res1"
  top : "block4-conv3"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 256
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block4-bn3"
  type: "BatchNorm"
  bottom: "block4-conv3"
  top: "block4-bn3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block4-relu3"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block4-relu3"
  bottom : "block4-bn3"
}

layer {
  name : "block4-conv4"
  type : "Convolution"
  bottom : "block4-relu3"
  top : "block4-conv4"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 256
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block4-bn4"
  type: "BatchNorm"
  bottom: "block4-conv4"
  top: "block4-bn4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block4-relu4"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block4-relu4"
  bottom : "block4-bn4"
}

layer {
  name: "block4-res2"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block4-res1"
  bottom: "block4-relu4"
  top: "block4-res2"
}

layer {
  name : "block4-conv5"
  type : "Convolution"
  bottom : "block4-res2"
  top : "block4-conv5"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 256
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block4-bn5"
  type: "BatchNorm"
  bottom: "block4-conv5"
  top: "block4-bn5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block4-relu5"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  top : "block4-relu5"
  bottom : "block4-bn5"
}

layer {
  name : "block4-conv6"
  type : "Convolution"
  bottom : "block4-relu5"
  top : "block4-conv6"
  param {
    lr_mult : 1
  }
  param {
    lr_mult : 2
  }
  convolution_param {
    num_output : 256
    pad : 1
    kernel_size : 3
    stride : 1
    weight_filler {
      type : "xavier"
    }
    bias_filler {
      type : "constant"
    }
  }
}
layer {
  name: "block4-bn6"
  type: "BatchNorm"
  bottom: "block4-conv6"
  top: "block4-bn6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "block4-relu6"
  type : "ReLU"
  relu_param {
    negative_slope : 0
  }
  bottom : "block4-bn6"
  top : "block4-relu6"
}

layer {
  name: "block4-res3"
  type: "Eltwise"
  eltwise_param: {
  	operation: SUM
  }
  bottom: "block4-res2"
  bottom: "block4-relu6"
  top: "block4-res3"
}

layer {
  name: "pool"
  type: "Pooling"
  bottom: "block4-res3"
  top: "pool"
  pooling_param {
    pool: AVE
    kernel_size: 2
    stride: 2
  }
}

layer {
  name: "flatten"
  type: "Flatten"
  bottom: "pool"
  top: "flatten"
}

layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "flatten"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "fc1-bn"
  type: "BatchNorm"
  bottom: "fc1"
  top: "fc1-bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "fc1-relu"
  type : "ReLU"
  bottom : "fc1-bn"
  top : "fc1-relu"
  relu_param {
    negative_slope : 0
  }
}

layer {
  name: "drop1"
  type: "Dropout"
  bottom: "fc1-relu"
  top: "drop1"
  dropout_param: {
  	dropout_ratio: 0.5
  }
}

layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "drop1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name: "fc2-bn"
  type: "BatchNorm"
  bottom: "fc2"
  top: "fc2-bn"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
}
layer {
  name : "fc2-relu"
  type : "ReLU"
  bottom : "fc2-bn"
  top : "fc2-relu"
  relu_param {
    negative_slope : 0
  }
}

layer {
  name: "drop2"
  type: "Dropout"
  bottom: "fc2-relu"
  top: "drop2"
  dropout_param: {
  	dropout_ratio: 0.5
  }
}

layer {
  name: "prob"
  type: "InnerProduct"
  bottom: "drop2"
  top: "prob"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}

layer {
  name : "accuracy"
  type : "Accuracy"
  bottom : "prob"
  bottom : "label"
  top : "accuracy"
  include {
    phase : TEST
  }
}
layer {
  name : "accuracy-top3"
  type : "Accuracy"
  bottom : "prob"
  bottom : "label"
  top : "accuracy-top3"
  accuracy_param: {
    top_k: 3
  }
  include {
    phase : TEST
  }
}
layer {
  name : "loss"
  type : "SoftmaxWithLoss"
  bottom : "prob"
  bottom : "label"
  top : "loss"
  softmax_param: {
      label_smooth: true
      label_smooth_factor: 0.001
  }
}
